import numpy as np
import pandas as pd 
import seaborn as sns

from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor

from sklearn.model_selection import KFold, cross_validate, GridSearchCV

train = pd.read_csv('/kaggle/input/playground-series-s5e9/train.csv', index_col=0)
test = pd.read_csv('/kaggle/input/playground-series-s5e9/test.csv')

missing_train = train.isna().sum()
print(missing_train[missing_train>0])
test.isna().sum()

X = train.drop('BeatsPerMinute', axis=1)
y = train.BeatsPerMinute

sns.histplot(y, kde=True)
sns.heatmap(train.corr(), annot=True)

models = {
    'LinearRegression' : LinearRegression(),
    'DecisionTreeRegressor' : DecisionTreeRegressor(),
    'Gradient Boosting': GradientBoostingRegressor(random_state=42),
    'XGBoost': XGBRegressor(tree_method="gpu_hist", predictor="gpu_predictor", random_state=42),
    'LightGBM': LGBMRegressor(device="gpu", random_state=42, verbose=-1),
    'CatBoost': CatBoostRegressor(task_type="GPU", iterations=300, random_state=42, verbose=0)
    "ElasticNet": ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)
}

scoring = {
     "mae": "neg_mean_absolute_error",
     "rmse": "neg_root_mean_squared_error",
     "r2": "r2"
}

kf = KFold(n_splits=5, shuffle=True,random_state=42)
models_rez = []

for model_name, model in models.items():
    model_scores = cross_validate(model, X, y, cv=kf, scoring=scoring)
    
    mae_scores = -model_scores["test_mae"]
    rmse_scores = -model_scores["test_rmse"]
    r2_scores = model_scores["test_r2"]

    models_rez.append({
        "Model": model_name,
        "MAE": mae_scores.mean(),
        "RMSE": rmse_scores.mean(),
        "RÂ²": r2_scores.mean()
    })
    
    print(f"{model_name}, MAE: {mae_scores.mean():.3f}, RMSE: {rmse_scores.mean():.3f}, R2: {r2_scores.mean():.3f}")

gbr = GradientBoostingRegressor(random_state=42)

param_grid = {
    "n_estimators": [200, 400, 600],
    "learning_rate": [0.01, 0.05, 0.1],
    "max_depth": [3, 5, 7]
}

grid_search = GridSearchCV(
    estimator=gbr,
    param_grid=param_grid,
    cv=5,
    scoring="neg_root_mean_squared_error",
    n_jobs=-1
)

grid_search.fit(X, y)

print("Best: ", grid_search.best_params_)

gbr = GradientBoostingRegressor(random_state=42,
                               n_estimators=400,
                               learning_rate=0.1)
gbr.fit(X, y)
y_pred = gbr.predict(test.drop('id', axis=1))

total = pd.DataFrame({'id':test.id, 'BeatsPerMinute': y_pred})
total.to_csv("Beats-per-Minute.csv", index=False)
total
